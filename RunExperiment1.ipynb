{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singeltask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "ITERATIONS = 5\n",
    "columns=[\"dataset\", \"accuracy\", \"precision\", \"recall\", \"duration\",\"epoch\"] #\"best_val_acc\", \"epoch\"]\n",
    "stl_results_fcn = pd.DataFrame(columns=columns)\n",
    "stl_results_res = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for idx, dataset in enumerate(['GunPoint','Beef','ECG200']): #'ECG5000']):\n",
    "\n",
    "    bac = 0; acc=0; precision=0; recall=0; duration=0\n",
    "\n",
    "    for itr in range(ITERATIONS): \n",
    "        fcn_best_model = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/fcn/fcn_{itr}/original/df_best_model.csv')\n",
    "        fcn_metrics = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/fcn/fcn_{itr}/original/task1_df_metrics.csv')\n",
    "        fcn_hist = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/fcn/fcn_{itr}/original/history.csv')\n",
    "\n",
    "        res_best_model = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/resnet/resnet_{itr}/original/df_best_model.csv')\n",
    "        res_metrics = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/resnet/resnet_{itr}/original/task1_df_metrics.csv')\n",
    "        res_hist = pd.read_csv(f'./results/ucr/{dataset}/experiment_1/resnet/resnet_{itr}/original/history.csv')\n",
    "\n",
    "        fcn_vals = [\n",
    "                    max(fcn_metrics[\"accuracy\"].values), max(fcn_metrics[\"precision\"]),\n",
    "                    max(fcn_metrics[\"recall\"].values), max(fcn_metrics[\"duration\"]), \n",
    "                    list(fcn_hist[\"val_accuracy\"]).index(max(fcn_hist[\"val_accuracy\"]))\n",
    "                    #max(fcn_hist[\"val_accuracy\"])\n",
    "                    ] \n",
    "        res_vals = [ \n",
    "                    res_metrics[\"accuracy\"].values[0], res_metrics[\"precision\"].values[0],\n",
    "                    res_metrics[\"recall\"].values[0], res_metrics[\"duration\"].values[0],\n",
    "                    list(res_hist[\"val_accuracy\"]).index(max(res_hist[\"val_accuracy\"]))\n",
    "                    #max(res_hist[\"val_accuracy\"])\n",
    "                    ]\n",
    "        #Read STL results for FCN classifier\n",
    "        if itr == 0:\n",
    "            stl_results_fcn.loc[idx] = [dataset] + fcn_vals\n",
    "            stl_results_res.loc[idx] = [dataset] + res_vals\n",
    "        else:\n",
    "            stl_results_fcn.loc[idx, columns[1:]] += fcn_vals\n",
    "            stl_results_res.loc[idx, columns[1:]] += res_vals\n",
    "\n",
    "    \n",
    "\n",
    "    stl_results_fcn.loc[idx, columns[1:]] /= ITERATIONS\n",
    "    stl_results_res.loc[idx, columns[1:]] /= ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_32648\\604288730.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  stl_results_fcn.to_latex(\"./results_csv/experiment1a/test_results_classification_fcn.tex\")\n",
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_32648\\604288730.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  stl_results_res.to_latex(\"./results_csv/experiment1a/test_results_classification_resnet.tex\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GunPoint</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.992405</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>70.777516</td>\n",
       "      <td>134.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beef</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.641308</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>55.480688</td>\n",
       "      <td>399.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.883365</td>\n",
       "      <td>0.876389</td>\n",
       "      <td>64.748806</td>\n",
       "      <td>105.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  accuracy  precision    recall   duration  epoch\n",
       "0  GunPoint  0.992000   0.992405  0.991892  70.777516  134.8\n",
       "1      Beef  0.546667   0.641308  0.546667  55.480688  399.8\n",
       "2    ECG200  0.890000   0.883365  0.876389  64.748806  105.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GunPoint</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>294.517580</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beef</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.803612</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>231.106733</td>\n",
       "      <td>310.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.871268</td>\n",
       "      <td>0.851736</td>\n",
       "      <td>233.101935</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  accuracy  precision    recall    duration  epoch\n",
       "0  GunPoint  0.989333   0.989744  0.989189  294.517580   63.0\n",
       "1      Beef  0.760000   0.803612  0.760000  231.106733  310.2\n",
       "2    ECG200  0.874000   0.871268  0.851736  233.101935  199.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stl_results_fcn.to_csv(\"./results_csv/experiment1a/test_results_classification_fcn.csv\")\n",
    "stl_results_fcn.to_latex(\"./results_csv/experiment1a/test_results_classification_fcn.tex\")\n",
    "stl_results_res.to_csv(\"./results_csv/experiment1a/test_results_classification_resnet.csv\")\n",
    "stl_results_res.to_latex(\"./results_csv/experiment1a/test_results_classification_resnet.tex\")\n",
    "display(stl_results_fcn)\n",
    "display(stl_results_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Classstats of Attribution methods (similar to DataExploration)\n",
    "\n",
    "- Plotting by class\n",
    "- Get MAE for all instances and classwise \n",
    "- Get Pearson for all instances and classwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import read_dataset\n",
    "import numpy as np\n",
    "#MAE over all dataset instances and classwise: \n",
    "root_dir = 'G:/Meine Ablage/master thesis/code/xai-tsc'\n",
    "archive_name = 'ucr'\n",
    "\n",
    "def calculate_inbetween_distance(dataset_name):\n",
    "    #load dataset\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, 'original', 1)\n",
    "    x_train, y_train, x_test, y_test = datasets_dict[dataset_name]\n",
    "    ylen = len(x_train[0])\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, 'fcn_ig_norm', ylen)\n",
    "    _, y_train_2, _, y_test_2 = datasets_dict[dataset_name]\n",
    "\n",
    "    output = []\n",
    "    for x_vals,y_vals in [[y_train_2,y_train],[y_test_2,y_test]]:\n",
    "        mean_inbetween_distance = 0 \n",
    "        mean_inbetween_distance_classwise = dict()\n",
    "        for x,y in zip(x_vals,y_vals):\n",
    "            if int(y) not in mean_inbetween_distance_classwise.keys(): mean_inbetween_distance_classwise[int(y)] = []\n",
    "            for x_n,y_n in zip(x_vals,y_vals):\n",
    "                if np.array_equal(x,x_n): continue\n",
    "                mae = mean_absolute_error(x,x_n)\n",
    "                if y == y_n: mean_inbetween_distance_classwise[int(y)].append(mae)\n",
    "                mean_inbetween_distance += mae\n",
    "        classwise_dist = []\n",
    "        for k in mean_inbetween_distance_classwise.keys():\n",
    "            mean_inbetween_distance_classwise[k] = sum(mean_inbetween_distance_classwise[k]) / len(mean_inbetween_distance_classwise[k])\n",
    "            classwise_dist.append(mean_inbetween_distance_classwise[k]) \n",
    "        mean_inbetween_distance = mean_inbetween_distance / len(x_vals)\n",
    "        output.append([mean_inbetween_distance, *classwise_dist])\n",
    "    return pd.DataFrame(output, columns = [\"MAE diff\", *[f'class {i}'for i in range(len(np.unique(y_train)))]])\n",
    "\n",
    "\n",
    "\n",
    "#Pearson over all dataset instances and classwise: \n",
    "def calculate_inbetween_corr_attribution_training_data(dataset_name):\n",
    "\n",
    "    #load dataset\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, 'original', 1)\n",
    "    x_train, y_train, x_test, y_test = datasets_dict[dataset_name]\n",
    "    ylen = len(x_train[0])\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, 'fcn_ig_norm', ylen)\n",
    "    _, y_train_2, _, y_test_2 = datasets_dict[dataset_name]\n",
    "\n",
    "    output = []\n",
    "    count = 0\n",
    "    for x_vals,y_vals in [[y_train_2,y_train],[y_test_2,y_test]]:\n",
    "        mean_inbetween_corr = 0 \n",
    "        mean_inbetween_corr_classwise = dict()\n",
    "        for x,y in zip(x_vals,y_vals):\n",
    "            if int(y) not in mean_inbetween_corr_classwise.keys(): mean_inbetween_corr_classwise[int(y)] = []\n",
    "            for x_n,y_n in zip(x_vals,y_vals):\n",
    "                if np.array_equal(x,x_n): continue\n",
    "                corr = np.corrcoef(x,x_n)[0,1]\n",
    "                if y == y_n: mean_inbetween_corr_classwise[int(y)].append(corr)\n",
    "                mean_inbetween_corr += corr\n",
    "                count += 1\n",
    "        classwise_dist = []\n",
    "        for k in mean_inbetween_corr_classwise.keys():\n",
    "            mean_inbetween_corr_classwise[k] = sum(mean_inbetween_corr_classwise[k]) / len(mean_inbetween_corr_classwise[k])\n",
    "            classwise_dist.append(mean_inbetween_corr_classwise[k]) \n",
    "        print(mean_inbetween_corr,len(x_vals))\n",
    "        mean_inbetween_corr = mean_inbetween_corr / count\n",
    "        output.append([mean_inbetween_corr, *classwise_dist])\n",
    "    return pd.DataFrame(output, columns = [\"Corr mean\", *[f'class {i}'for i in range(len(np.unique(y_train)))]])\n",
    "\n",
    "\n",
    "#calculate_inbetween_distance(\"GunPoint\")\n",
    "#display(\"GunPoint\", calculate_inbetween_corr_attribution_training_data(\"GunPoint\"))\n",
    "#display(\"ECG200\", calculate_inbetween_corr_attribution_training_data(\"ECG200\"))\n",
    "#display(\"Beef\", calculate_inbetween_corr_attribution_training_data(\"Beef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.09338070167998 50\n",
      "197.8358348209597 150\n",
      "1216.5573310822285 100\n",
      "1000.6247737837285 100\n",
      "31.929657372482644 30\n",
      "110.14902383402497 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_11696\\1716055858.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pd.concat([calculate_inbetween_corr_attribution_training_data(\"GunPoint\"),calculate_inbetween_corr_attribution_training_data(\"ECG200\"),calculate_inbetween_corr_attribution_training_data(\"Beef\")],axis=1).round(2).to_latex(\"./results_csv/Experiment1a/corr_mean_classinter.tex\")\n"
     ]
    }
   ],
   "source": [
    "pd.concat([calculate_inbetween_corr_attribution_training_data(\"GunPoint\"),calculate_inbetween_corr_attribution_training_data(\"ECG200\"),calculate_inbetween_corr_attribution_training_data(\"Beef\")],axis=1).round(2).to_latex(\"./results_csv/Experiment1a/corr_mean_classinter.tex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Similarity of Attribution methods\n",
    "\n",
    "- raw unscaled attribution vectors\n",
    "- pearson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>correlation</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GunPoint</td>\n",
       "      <td>0.043283</td>\n",
       "      <td>0.016084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beef</td>\n",
       "      <td>0.115806</td>\n",
       "      <td>0.004116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>0.125237</td>\n",
       "      <td>0.019328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECG5000</td>\n",
       "      <td>0.093271</td>\n",
       "      <td>0.014634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  correlation       mse\n",
       "0  GunPoint     0.043283  0.016084\n",
       "1      Beef     0.115806  0.004116\n",
       "2    ECG200     0.125237  0.019328\n",
       "3   ECG5000     0.093271  0.014634"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.utils import read_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "archive = 'ucr'\n",
    "dataset_name = 'GunPoint'\n",
    "data_p = 'G:/Meine Ablage/master thesis/code/xai-tsc'\n",
    "\n",
    "train_val = []\n",
    "test_val  = []\n",
    "\n",
    "for idx, dataset in enumerate(os.listdir('./archives/ucr')):\n",
    "    ylen = 1\n",
    "    data = read_dataset(data_p, archive, dataset, 'original', ylen)[dataset]\n",
    "    ylen = len(data[0][0])\n",
    "    try:\n",
    "        _,cy,_,cy1 = read_dataset(data_p, archive, dataset, 'fcn_cam_norm', ylen)[dataset]\n",
    "        _,igy,_,igy1 = read_dataset(data_p, archive, dataset, 'fcn_ig_norm', ylen)[dataset]\n",
    "        train_val.append([dataset,np.mean(np.corrcoef(cy, igy, rowvar=True)), np.mean(np.square(cy- igy))])\n",
    "        test_val.append([dataset,np.mean(np.corrcoef(cy1,igy1,rowvar=True)),  np.mean(np.square(cy1- igy1))])\n",
    "    except Exception as e: \n",
    "        #print(dataset,\"error\", e)\n",
    "        pass\n",
    "\n",
    "    \n",
    "pd.DataFrame(train_val,columns=[\"dataset\", \"correlation\",\"mse\"])\n",
    "pd.DataFrame(test_val,columns=[\"dataset\", \"correlation\", \"mse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the similarity of attributions after differnet trainings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/GunPoint//experiment_1/resnet/resnet_0/original/best_model.hdf5\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024F3055E5F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/GunPoint//experiment_1/resnet/resnet_1/original/best_model.hdf5\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/GunPoint//experiment_1/resnet/resnet_2/original/best_model.hdf5\n",
      "2/2 [==============================] - 1s 33ms/step\n",
      "5/5 [==============================] - 0s 33ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/GunPoint//experiment_1/resnet/resnet_3/original/best_model.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/GunPoint//experiment_1/resnet/resnet_4/original/best_model.hdf5\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/ECG200//experiment_1/resnet/resnet_0/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/ECG200//experiment_1/resnet/resnet_1/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 18ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/ECG200//experiment_1/resnet/resnet_2/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/ECG200//experiment_1/resnet/resnet_3/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "from utils.explanations import calculate_ig_attributions, norm\n",
    "import matplotlib.pyplot as plt\n",
    "train_att_array = []\n",
    "test_att_array = []\n",
    "ITERATIONS = 5\n",
    "model_type =\"resnet\"\n",
    "form = \"norm\"\n",
    "model = \"resnet\"\n",
    "expl_type  = \"ig_norm\"\n",
    "\n",
    "correlations = dict()\n",
    "train_att_array = []\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))\n",
    "for idx, dataset in enumerate(['GunPoint','ECG200','Beef']):\n",
    "    #read baseline attributions \n",
    "    #len of datasets GunPoint, ECG200, Beef\n",
    "    timeseries_len = [150,96,470]\n",
    "    datasets_len_train = [50,100,30]\n",
    "    datasets_len_test = [150,100,30]\n",
    "    data_stl  = read_dataset(data_p, archive, dataset, f'{model_type}_{expl_type}',timeseries_len[idx])[dataset]\n",
    "    correlations[dataset] = {\n",
    "        \"train\" : [],\n",
    "        \"test\" :  []\n",
    "    }\n",
    "    axes[idx].set_title(f\"{dataset}\")\n",
    "    axes[idx].plot(np.arange(len(data_stl[3][0])),data_stl[3][0])\n",
    "    #Calculate attributions \n",
    "    for itr in range(ITERATIONS):\n",
    "        #calculate ig attributions\n",
    "        attributions = calculate_ig_attributions(root_dir, archive, f\"{model}_{itr}\", dataset, f\"original\", task=0, experiment=1,scale=\"normalized\")\n",
    "        # get values \n",
    "        train_raw_att_vals = np.array([att[2] for att in attributions[0]]) \n",
    "        test_raw_att_vals = np.array([att[2] for att in attributions[1]]) \n",
    "        train_corr = 0; test_corr = 0\n",
    "        #train data\n",
    "        for ts1, ts2 in zip(data_stl[1],train_raw_att_vals):\n",
    "            train_corr += np.corrcoef(ts1,norm(ts2))[0,1]\n",
    "        for ts1, ts2 in zip(data_stl[3],test_raw_att_vals):\n",
    "            test_corr += np.corrcoef(ts1,norm(ts2))[0,1]\n",
    "\n",
    "        train_corr /= datasets_len_train[idx]\n",
    "        test_corr /= datasets_len_test[idx]\n",
    "\n",
    "        #plot first time series for visualization\n",
    "        axes[idx].plot(np.arange(len(test_raw_att_vals[0])),norm(test_raw_att_vals[0]), label=f\"TS {0} / PCC {np.round(np.corrcoef(data_stl[3][0],norm(test_raw_att_vals[0]))[0,1],3)}\")\n",
    "        axes[idx].legend(loc=\"lower right\")\n",
    "\n",
    "        correlations[dataset][\"train\"].append(train_corr)\n",
    "        correlations[dataset][\"test\"].append(test_corr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858113</td>\n",
       "      <td>0.830577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569260</td>\n",
       "      <td>0.542645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797936</td>\n",
       "      <td>0.758310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754376</td>\n",
       "      <td>0.717475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train      test\n",
       "0  0.858113  0.830577\n",
       "1  1.000000  1.000000\n",
       "2  0.569260  0.542645\n",
       "3  0.797936  0.758310\n",
       "4  0.754376  0.717475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887175</td>\n",
       "      <td>0.854940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.886423</td>\n",
       "      <td>0.847648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883240</td>\n",
       "      <td>0.845287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887842</td>\n",
       "      <td>0.852217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train      test\n",
       "0  0.887175  0.854940\n",
       "1  1.000000  1.000000\n",
       "2  0.886423  0.847648\n",
       "3  0.883240  0.845287\n",
       "4  0.887842  0.852217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.437852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304517</td>\n",
       "      <td>0.099338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792066</td>\n",
       "      <td>0.557593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055896</td>\n",
       "      <td>0.149743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train      test\n",
       "0  0.719655  0.437852\n",
       "1  1.000000  1.000000\n",
       "2  0.304517  0.099338\n",
       "3  0.792066  0.557593\n",
       "4  0.055896  0.149743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_11696\\3523802684.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pd.concat([pd.DataFrame(correlations[\"GunPoint\"]), pd.DataFrame(correlations[\"ECG200\"]),pd.DataFrame(correlations[\"Beef\"])],axis=1).to_latex(\"./results_csv/Experiment1a/intersimilarity.tex\")\n"
     ]
    }
   ],
   "source": [
    "display(pd.DataFrame(correlations[\"GunPoint\"]))\n",
    "display(pd.DataFrame(correlations[\"ECG200\"]))\n",
    "display(pd.DataFrame(correlations[\"Beef\"]))\n",
    "#intersimilarity fcn\n",
    "#pd.concat([pd.DataFrame(correlations[\"GunPoint\"]), pd.DataFrame(correlations[\"ECG200\"]),pd.DataFrame(correlations[\"Beef\"])],axis=1).to_latex(\"./results_csv/Experiment1a/intersimilarity.tex\")\n",
    "# intersimilarity resnet\n",
    "pd.concat([pd.DataFrame(correlations[\"GunPoint\"]), pd.DataFrame(correlations[\"ECG200\"]),pd.DataFrame(correlations[\"Beef\"])],axis=1).to_latex(\"./results_csv/Experiment1a/intersimilarity_resnet.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_att_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcualte Custom Metrics for Attribution Prediction Task \n",
    "\n",
    "\n",
    "<text color=\"red\">rework required</text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG200\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from utils.explanations import integrated_gradients\n",
    "from keras.utils import CustomObjectScope\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from utils.explanations import minmax_norm\n",
    "from utils.explanations import calculate_ig_attributions, calculate_cam_attributions\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from utils.utils import read_dataset\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load model to calculate custom metrics \n",
    "def load_model(root_dir, archive_name, dataset_name, classifier, data_source): \n",
    "    with CustomObjectScope({'InstanceNormalization':tfa.layers.InstanceNormalization()}):\n",
    "        model_path = f'{root_dir}/results/{archive_name}/{dataset_name}/' \\\n",
    "                                                + f'{classifier.split(\"_\")[0]}/{classifier}/{data_source}/' \\\n",
    "                                                + f'best_model.hdf5'\n",
    "        model =keras.models.load_model(model_path ,compile=False)\n",
    "        return model\n",
    "    \n",
    "\n",
    "def norm(values): \n",
    "    if not type(values) == np.ndarray:\n",
    "        return normalize(values.numpy().reshape(1,-1))[0]\n",
    "    else: \n",
    "        return normalize(values.reshape(1,-1))[0]\n",
    "    \n",
    "#define shared trunk\n",
    "network = 'fcn' \n",
    "expl_type = 'ig_norm'\n",
    "#store custom metrics for model\n",
    "models_train  = dict()\n",
    "models_test   = dict()\n",
    "# Loop over data\n",
    "\n",
    "\n",
    "columns = [\"dataset\",\"model\", \"pm1\",  \"mm1\" ]\n",
    "models_train =  pd.DataFrame(columns=columns)\n",
    "models_test = pd.DataFrame(columns=columns)\n",
    "ITERATIONS = 2\n",
    "\n",
    "position = 0\n",
    "\n",
    "\n",
    "for idx, dataset in enumerate(['ECG200']):#enumerate(os.listdir('./archives/ucr')):,'Coffee','Beef','ECG200'\n",
    "    print(dataset)\n",
    "    ylen = 1\n",
    "    #Just for now:\n",
    "\n",
    "    data = read_dataset(data_p, archive, dataset, 'original', ylen)[dataset]\n",
    "    #assertion,each ts has same length\n",
    "    ylen = len(data[0][0])\n",
    "\n",
    "    for model in ['fcn_mt_conv']: #'fcn_mt_linear']: #['fcn_mt_ae','fcn_mt_conv', 'fcn_mt_linear']: \n",
    "        model_type = model.split('_')[0] \n",
    "        for itr in range(ITERATIONS): \n",
    "            data_stl  = read_dataset(data_p, archive, dataset, f'{model_type}_{expl_type}', ylen)[dataset]\n",
    "            model_link  = f'./results/ucr/{dataset}/experiment_1/{model_type}/{model}_{itr}/{model_type}_{expl_type}/best_model.hdf5'\n",
    "            loaded_model = keras.models.load_model(model_link ,compile=False)\n",
    "            for t in [1,3]:\n",
    "                tc = t \n",
    "                #Pearson and mse [p,m]\n",
    "                pm1 = 0;  mm1 = 0 \n",
    "                #predict values for all timeseries \n",
    "                pred = loaded_model.predict(data[t-1])\n",
    "                #run loop\n",
    "                for ts in range(len(data[t])):                \n",
    "                    #structure of attributions 0 --> train 1 --> test set\n",
    "                    pm1 += np.corrcoef(pred[1][ts].flatten(),data_stl[t][ts])[0,1]\n",
    "                    mm1 += mean_squared_error(pred[1][ts].flatten(),data_stl[t][ts])\n",
    "                #Init for model \n",
    "                l = len(data[t])\n",
    "                if itr == 0:\n",
    "                    if t == 1: \n",
    "                        models_train.loc[position] = [dataset, model, pm1/l, mm1/l]\n",
    "                    else: \n",
    "                        models_test.loc[position]  =[dataset, model, pm1/l, mm1/l]\n",
    "                else:\n",
    "                    if t == 1: \n",
    "                        models_train.loc[position, columns[2:]] += [(pm1/l),(mm1/l)]\n",
    "                    else:                                                      \n",
    "                        models_test.loc[position, columns[2:]] += [(pm1/l), (mm1/l)]\n",
    "        position += 1\n",
    "    position += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>pm1</th>\n",
       "      <th>mm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>fcn_mt_conv</td>\n",
       "      <td>1.8139</td>\n",
       "      <td>0.00381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset        model     pm1      mm1\n",
       "0  ECG200  fcn_mt_conv  1.8139  0.00381"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>pm1</th>\n",
       "      <th>mm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECG200</td>\n",
       "      <td>fcn_mt_conv</td>\n",
       "      <td>1.089257</td>\n",
       "      <td>0.016824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset        model       pm1       mm1\n",
       "0  ECG200  fcn_mt_conv  1.089257  0.016824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.8139000164750472"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display(pd.DataFrame(models_train))\n",
    "display(pd.DataFrame(models_test))\n",
    "\n",
    "\n",
    "models_train[\"pm1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2323141394948575, 0.8405306691596884, 0.6002678690367294)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"./results_csv/Experiment2/test_data_5runs.csv\")[\"pm3\"].min(), pd.read_csv(\"./results_csv/Experiment2/test_data_5runs.csv\")[\"pm3\"].max(),pd.read_csv(\"./results_csv/Experiment2/test_data_5runs.csv\")[\"pm3\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_32648\\2035812856.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pd.DataFrame(models_test).T.to_latex('./results_csv/experiment1c/test_results_fcn.tex')\n"
     ]
    }
   ],
   "source": [
    "#pd.DataFrame(models_test).T.to_latex('./results_csv/experiment1c/test_results_fcn.tex')\n",
    "#pd.DataFrame(models_test).T.to_csv('./results_csv/experiment1c/test_results_fcn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>ECG200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>fcn_mt_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm1</th>\n",
       "      <td>0.999297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm1</th>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "dataset     ECG200\n",
       "model    fcn_mt_nn\n",
       "pm1       0.999297\n",
       "mm1       0.000013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>ECG200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>fcn_mt_nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm1</th>\n",
       "      <td>0.483942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mm1</th>\n",
       "      <td>0.00817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "dataset     ECG200\n",
       "model    fcn_mt_nn\n",
       "pm1       0.483942\n",
       "mm1        0.00817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "models_train = pd.read_csv\n",
    "display(pd.DataFrame(models_train).T)\n",
    "display(pd.DataFrame(models_test).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_32648\\2700811303.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pd.DataFrame(models_test).T.to_latex('./results_csv/experiment1c/test_results_resnet.tex')\n"
     ]
    }
   ],
   "source": [
    "#pd.DataFrame(models_test).T.to_latex('./results_csv/experiment1c/test_results_resnet.tex')\n",
    "#pd.DataFrame(models_test).T.to_csv('./results_csv/experiment1c/test_results_resnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/ucr/GunPoint/experiment_1/fcn/fcn_mt_ae_4/fcn_ig_norm/best_model.hdf5\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc ucr GunPoint original 1\n",
      "2/2 [==============================] - 1s 9ms/step\n",
      "5/5 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr Mean</th>\n",
       "      <th>class 0</th>\n",
       "      <th>class 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990986</td>\n",
       "      <td>0.990329</td>\n",
       "      <td>0.991698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.826811</td>\n",
       "      <td>0.837033</td>\n",
       "      <td>0.816312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Corr Mean   class 0   class 1\n",
       "0   0.990986  0.990329  0.991698\n",
       "1   0.826811  0.837033  0.816312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.09338070167998 50\n",
      "197.8358348209597 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr diff</th>\n",
       "      <th>class 0</th>\n",
       "      <th>class 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030650</td>\n",
       "      <td>0.109364</td>\n",
       "      <td>0.089975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.068820</td>\n",
       "      <td>0.077066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Corr diff   class 0   class 1\n",
       "0   0.030650  0.109364  0.089975\n",
       "1   0.007977  0.068820  0.077066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_inbetween_corr(dataset_name, model, expl_type):\n",
    "    model_type = model.split(\"_\")[0]\n",
    "    #load dataset\n",
    "    ig_link  = f'./results/ucr/{dataset_name}/experiment_1/{model_type}/{model}_{itr}/{expl_type}/best_model.hdf5'\n",
    "    print(ig_link)\n",
    "    loaded_model = keras.models.load_model(ig_link ,compile=False)\n",
    "\n",
    "    print(root_dir, archive_name, dataset_name, 'original', 1)\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, 'original', 1)\n",
    "    x_train, y_train, x_test, y_test = datasets_dict[dataset_name]\n",
    "    ylen = len(x_train[0])\n",
    "\n",
    "    datasets_dict = read_dataset(root_dir, archive_name, dataset_name, expl_type, ylen)\n",
    "    _, y_train_2, _, y_test_2 = datasets_dict[dataset_name]\n",
    "\n",
    "    output = []\n",
    "    for x_vals,y_vals_2, y_vals in [[x_train, y_train_2,y_train],[x_test,y_test_2,y_test]]:\n",
    "        mean_inbetween_corr = 0 \n",
    "        mean_inbetween_corr_classwise = dict()\n",
    "        pred = loaded_model.predict(x_vals)[1]\n",
    "\n",
    "        for pr,y2,y in zip(pred,y_vals_2, y_vals):\n",
    "            if int(y) not in mean_inbetween_corr_classwise.keys(): mean_inbetween_corr_classwise[int(y)] = []\n",
    "            corr = np.corrcoef(y2,pr.flatten())[0,1]\n",
    "            mean_inbetween_corr_classwise[int(y)].append(corr)\n",
    "            mean_inbetween_corr += corr\n",
    "        classwise_dist = []\n",
    "        for k in mean_inbetween_corr_classwise.keys():\n",
    "            mean_inbetween_corr_classwise[k] = sum(mean_inbetween_corr_classwise[k]) / len(mean_inbetween_corr_classwise[k])\n",
    "            classwise_dist.append(mean_inbetween_corr_classwise[k]) \n",
    "        mean_inbetween_corr = mean_inbetween_corr / len(x_vals)\n",
    "        output.append([mean_inbetween_corr, *classwise_dist])\n",
    "    return pd.DataFrame(output, columns = [\"Corr Mean\", *[f'class {i}'for i in range(len(np.unique(y_train)))]])\n",
    "\n",
    "\n",
    "#calculate_inbetween_distance(\"GunPoint\")\n",
    "display(calculate_inbetween_corr(\"GunPoint\", \"fcn_mt_ae\", \"fcn_ig_norm\"))\n",
    "display(calculate_inbetween_corr_attribution_training_data(\"GunPoint\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "def prepare_visualize_attribution(ts,attribution):\n",
    "    max_length = 2000    \n",
    "    #prepare values\n",
    "    minimum = np.min(attribution)\n",
    "    cas = attribution - minimum\n",
    "    cas = cas / max(cas)\n",
    "    cas = cas * 100\n",
    "    xv= np.linspace(0, len(ts) - 1, max_length, endpoint=True)\n",
    "    f = interp1d(range(len(ts)),ts)\n",
    "    yv = f(xv)\n",
    "    f = interp1d(range(len(ts)),cas)\n",
    "    cas = f(xv).astype(int)\n",
    "    return xv,yv,cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc/results/ucr/ECG200//experiment_1/fcn/fcn_mt_ae_0/fcn_ig_norm/best_model.hdf5\n",
      "4/4 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__integral_approximation() takes from -2 to 1 positional arguments but 7 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[255], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     63\u001b[0m         plt\u001b[39m.\u001b[39mdraw()\n\u001b[1;32m---> 65\u001b[0m visualize_experiment_1(\u001b[39m'\u001b[39;49m\u001b[39mECG200\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mresnet_mt_ae\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m10\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[255], line 33\u001b[0m, in \u001b[0;36mvisualize_experiment_1\u001b[1;34m(dataset, model, ts, train)\u001b[0m\n\u001b[0;32m     31\u001b[0m pred \u001b[39m=\u001b[39m ig_model\u001b[39m.\u001b[39mpredict(x)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[39m#Get attribution values used for prediction\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m stl_pred_att \u001b[39m=\u001b[39m calculate_ig_attributions(data_p, archive, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel\u001b[39m}\u001b[39;49;00m\u001b[39m_0\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataset, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_type\u001b[39m}\u001b[39;49;00m\u001b[39m_ig_norm\u001b[39;49m\u001b[39m\"\u001b[39;49m, task\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     34\u001b[0m \u001b[39m#Get attributen used for specific time series\u001b[39;00m\n\u001b[0;32m     35\u001b[0m pred_att \u001b[39m=\u001b[39m stl_pred_att[\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mg:\\Meine Ablage\\master thesis\\code\\xai-tsc\\utils\\explanations.py:202\u001b[0m, in \u001b[0;36mcalculate_ig_attributions\u001b[1;34m(root_dir, archive_name, classifier, dataset_name, data_source, datasets_dict, task, experiment, scale)\u001b[0m\n\u001b[0;32m    200\u001b[0m attr \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m idx,ts \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_vals):\n\u001b[1;32m--> 202\u001b[0m     series \u001b[39m=\u001b[39m ts\n\u001b[0;32m    203\u001b[0m     ig_att \u001b[39m=\u001b[39m integrated_gradients(model,baseline,series\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    204\u001b[0m                                 np\u001b[39m.\u001b[39margmax(pred[idx]),\n\u001b[0;32m    205\u001b[0m                                 task\u001b[39m=\u001b[39mtask)\n\u001b[0;32m    206\u001b[0m                                 \u001b[39m#optimize for true values\u001b[39;00m\n\u001b[0;32m    207\u001b[0m                                 \u001b[39m#y_pos.index(y_vals[idx]),\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__integral_approximation() takes from -2 to 1 positional arguments but 7 were given\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkwAAAGyCAYAAACmzei1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoOElEQVR4nO3df2zV9b0/8Feh0Kr39izCrCDIYFc3NjJ2KYFRLlnm1Ro0LiS7sYs3ol5N1my7CL16B+NGBjFptpuZOzfBbYJmCbrGn/GPXkf/uBdRuD/glmUZJC7CtbC1kmJsUXeLwOf7h5feb9fiOLX9nPa8H4/k/NG370/P+7xTeT+T5/mcU5FlWRYAAAAAAAAJm1TqBQAAAAAAAJSawgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEiewgQAAAAAAEhe0YXJyy+/HLfcckvMnDkzKioq4oUXXvij1+zevTvq6uqiuro65s2bF48++uhI1goAIIsAACUliwBA+Sq6MHn33Xdj4cKF8aMf/eii5h89ejRuuummWLFiRXR0dMS3v/3tWLNmTTz77LNFLxYAQBYBAEpJFgGA8lWRZVk24osrKuL555+PVatWXXDOt771rXjxxRfj8OHDA2NNTU3xy1/+Mvbt2zfSpwYAkEUAgJKSRQCgvFSO9RPs27cvGhoaBo3deOONsX379nj//fdjypQpQ67p7++P/v7+gZ/PnTsXb731VkybNi0qKirGeskAMCFkWRanTp2KmTNnxqRJvpbsQmQRABgbssjFkUUAYGyMRRYZ88Kku7s7amtrB43V1tbGmTNnoqenJ2bMmDHkmpaWlti8efNYLw0AysKxY8di1qxZpV7GuCWLAMDYkkU+nCwCAGNrNLPImBcmETHk3Q/nPwXsQu+K2LBhQzQ3Nw/83NvbG1dffXUcO3Ysampqxm6hADCB9PX1xezZs+NP//RPS72UcU8WAYDRJ4tcPFkEAEbfWGSRMS9Mrrzyyuju7h40duLEiaisrIxp06YNe01VVVVUVVUNGa+pqREMAOAP+FiGDyeLAMDYkkU+nCwCAGNrNLPImH/I6LJly6K9vX3Q2K5du2Lx4sXDfk4nAMBokkUAgFKSRQBg4ii6MHnnnXfi4MGDcfDgwYiIOHr0aBw8eDA6Ozsj4oPbRlevXj0wv6mpKd54441obm6Ow4cPx44dO2L79u1x3333jc4rAACSIosAAKUkiwBA+Sr6I7n2798fX/rSlwZ+Pv+ZmnfccUc88cQT0dXVNRASIiLmzp0bbW1tsW7dunjkkUdi5syZ8fDDD8dXvvKVUVg+AJAaWQQAKCVZBADKV0V2/pvGxrG+vr4oFArR29vrszoB4H85H/NjrwFgKOdjfuw1AAw1FufjmH+HCQAAAAAAwHinMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJKnMAEAAAAAAJI3osJk69atMXfu3Kiuro66urrYs2fPh87fuXNnLFy4MC699NKYMWNG3HXXXXHy5MkRLRgAQBYBAEpJFgGA8lR0YdLa2hpr166NjRs3RkdHR6xYsSJWrlwZnZ2dw85/5ZVXYvXq1XH33XfHr3/963j66afjP//zP+Oee+75yIsHANIjiwAApSSLAED5Kroweeihh+Luu++Oe+65J+bPnx//9E//FLNnz45t27YNO//f/u3f4hOf+ESsWbMm5s6dG3/xF38RX/va12L//v0fefEAQHpkEQCglGQRAChfRRUmp0+fjgMHDkRDQ8Og8YaGhti7d++w19TX18fx48ejra0tsiyLN998M5555pm4+eabL/g8/f390dfXN+gBACCLAAClJIsAQHkrqjDp6emJs2fPRm1t7aDx2tra6O7uHvaa+vr62LlzZzQ2NsbUqVPjyiuvjI997GPxwx/+8ILP09LSEoVCYeAxe/bsYpYJAJQpWQQAKCVZBADK24i+9L2iomLQz1mWDRk779ChQ7FmzZp44IEH4sCBA/HSSy/F0aNHo6mp6YK/f8OGDdHb2zvwOHbs2EiWCQCUKVkEACglWQQAylNlMZOnT58ekydPHvKuiRMnTgx5d8V5LS0tsXz58rj//vsjIuJzn/tcXHbZZbFixYp48MEHY8aMGUOuqaqqiqqqqmKWBgAkQBYBAEpJFgGA8lbUHSZTp06Nurq6aG9vHzTe3t4e9fX1w17z3nvvxaRJg59m8uTJEfHBOzAAAC6WLAIAlJIsAgDlreiP5Gpubo7HHnssduzYEYcPH45169ZFZ2fnwK2kGzZsiNWrVw/Mv+WWW+K5556Lbdu2xZEjR+LVV1+NNWvWxJIlS2LmzJmj90oAgCTIIgBAKckiAFC+ivpIroiIxsbGOHnyZGzZsiW6urpiwYIF0dbWFnPmzImIiK6urujs7ByYf+edd8apU6fiRz/6Ufzd3/1dfOxjH4vrrrsuvvvd747eqwAAkiGLAAClJIsAQPmqyCbA/Z99fX1RKBSit7c3ampqSr0cABgXnI/5sdcAMJTzMT/2GgCGGovzseiP5AIAAAAAACg3ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5ChMAAAAAACB5IypMtm7dGnPnzo3q6uqoq6uLPXv2fOj8/v7+2LhxY8yZMyeqqqrik5/8ZOzYsWNECwYAkEUAgFKSRQCgPFUWe0Fra2usXbs2tm7dGsuXL48f//jHsXLlyjh06FBcffXVw15z6623xptvvhnbt2+PP/uzP4sTJ07EmTNnPvLiAYD0yCIAQCnJIgBQviqyLMuKuWDp0qWxaNGi2LZt28DY/PnzY9WqVdHS0jJk/ksvvRRf/epX48iRI3H55ZePaJF9fX1RKBSit7c3ampqRvQ7AKDcpHo+yiIAMD6kej7KIgAwPozF+VjUR3KdPn06Dhw4EA0NDYPGGxoaYu/evcNe8+KLL8bixYvje9/7Xlx11VVx7bXXxn333Re///3vL/g8/f390dfXN+gBACCLAAClJIsAQHkr6iO5enp64uzZs1FbWztovLa2Nrq7u4e95siRI/HKK69EdXV1PP/889HT0xNf//rX46233rrg53W2tLTE5s2bi1kaAJAAWQQAKCVZBADK24i+9L2iomLQz1mWDRk779y5c1FRURE7d+6MJUuWxE033RQPPfRQPPHEExd8N8WGDRuit7d34HHs2LGRLBMAKFOyCABQSrIIAJSnou4wmT59ekyePHnIuyZOnDgx5N0V582YMSOuuuqqKBQKA2Pz58+PLMvi+PHjcc011wy5pqqqKqqqqopZGgCQAFkEACglWQQAyltRd5hMnTo16urqor29fdB4e3t71NfXD3vN8uXL43e/+1288847A2OvvfZaTJo0KWbNmjWCJQMAqZJFAIBSkkUAoLwV/ZFczc3N8dhjj8WOHTvi8OHDsW7duujs7IympqaI+OC20dWrVw/Mv+2222LatGlx1113xaFDh+Lll1+O+++/P/7mb/4mLrnkktF7JQBAEmQRAKCUZBEAKF9FfSRXRERjY2OcPHkytmzZEl1dXbFgwYJoa2uLOXPmREREV1dXdHZ2Dsz/kz/5k2hvb4+//du/jcWLF8e0adPi1ltvjQcffHD0XgUAkAxZBAAoJVkEAMpXRZZlWakX8cf09fVFoVCI3t7eqKmpKfVyAGBccD7mx14DwFDOx/zYawAYaizOx6I/kgsAAAAAAKDcKEwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkKUwAAAAAAIDkjagw2bp1a8ydOzeqq6ujrq4u9uzZc1HXvfrqq1FZWRmf//znR/K0AAARIYsAAKUliwBAeSq6MGltbY21a9fGxo0bo6OjI1asWBErV66Mzs7OD72ut7c3Vq9eHX/5l3854sUCAMgiAEApySIAUL4qsizLirlg6dKlsWjRoti2bdvA2Pz582PVqlXR0tJyweu++tWvxjXXXBOTJ0+OF154IQ4ePHjRz9nX1xeFQiF6e3ujpqammOUCQNlK9XyURQBgfEj1fJRFAGB8GIvzsag7TE6fPh0HDhyIhoaGQeMNDQ2xd+/eC173+OOPx+uvvx6bNm26qOfp7++Pvr6+QQ8AAFkEACglWQQAyltRhUlPT0+cPXs2amtrB43X1tZGd3f3sNf85je/ifXr18fOnTujsrLyop6npaUlCoXCwGP27NnFLBMAKFOyCABQSrIIAJS3EX3pe0VFxaCfsywbMhYRcfbs2bjtttti8+bNce21117079+wYUP09vYOPI4dOzaSZQIAZUoWAQBKSRYBgPJ0cW9t+F/Tp0+PyZMnD3nXxIkTJ4a8uyIi4tSpU7F///7o6OiIb37zmxERce7cuciyLCorK2PXrl1x3XXXDbmuqqoqqqqqilkaAJAAWQQAKCVZBADKW1F3mEydOjXq6uqivb190Hh7e3vU19cPmV9TUxO/+tWv4uDBgwOPpqam+NSnPhUHDx6MpUuXfrTVAwBJkUUAgFKSRQCgvBV1h0lERHNzc9x+++2xePHiWLZsWfzkJz+Jzs7OaGpqiogPbhv97W9/Gz/72c9i0qRJsWDBgkHXX3HFFVFdXT1kHADgYsgiAEApySIAUL6KLkwaGxvj5MmTsWXLlujq6ooFCxZEW1tbzJkzJyIiurq6orOzc9QXCgAQIYsAAKUliwBA+arIsiwr9SL+mL6+vigUCtHb2xs1NTWlXg4AjAvOx/zYawAYyvmYH3sNAEONxflY1HeYAAAAAAAAlCOFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkDyFCQAAAAAAkLwRFSZbt26NuXPnRnV1ddTV1cWePXsuOPe5556LG264IT7+8Y9HTU1NLFu2LH7xi1+MeMEAALIIAFBKsggAlKeiC5PW1tZYu3ZtbNy4MTo6OmLFihWxcuXK6OzsHHb+yy+/HDfccEO0tbXFgQMH4ktf+lLccsst0dHR8ZEXDwCkRxYBAEpJFgGA8lWRZVlWzAVLly6NRYsWxbZt2wbG5s+fH6tWrYqWlpaL+h2f/exno7GxMR544IGLmt/X1xeFQiF6e3ujpqammOUCQNlK9XyURQBgfEj1fJRFAGB8GIvzsag7TE6fPh0HDhyIhoaGQeMNDQ2xd+/ei/od586di1OnTsXll19+wTn9/f3R19c36AEAIIsAAKUkiwBAeSuqMOnp6YmzZ89GbW3toPHa2tro7u6+qN/x/e9/P95999249dZbLzinpaUlCoXCwGP27NnFLBMAKFOyCABQSrIIAJS3EX3pe0VFxaCfsywbMjacp556Kr7zne9Ea2trXHHFFRect2HDhujt7R14HDt2bCTLBADKlCwCAJSSLAIA5amymMnTp0+PyZMnD3nXxIkTJ4a8u+IPtba2xt133x1PP/10XH/99R86t6qqKqqqqopZGgCQAFkEACglWQQAyltRd5hMnTo16urqor29fdB4e3t71NfXX/C6p556Ku6888548skn4+abbx7ZSgGA5MkiAEApySIAUN6KusMkIqK5uTluv/32WLx4cSxbtix+8pOfRGdnZzQ1NUXEB7eN/va3v42f/exnEfFBKFi9enX84Ac/iC984QsD78K45JJLolAojOJLAQBSIIsAAKUkiwBA+Sq6MGlsbIyTJ0/Gli1boqurKxYsWBBtbW0xZ86ciIjo6uqKzs7Ogfk//vGP48yZM/GNb3wjvvGNbwyM33HHHfHEE0989FcAACRFFgEASkkWAYDyVZFlWVbqRfwxfX19USgUore3N2pqakq9HAAYF5yP+bHXADCU8zE/9hoAhhqL87Go7zABAAAAAAAoRwoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeQoTAAAAAAAgeSMqTLZu3Rpz586N6urqqKuriz179nzo/N27d0ddXV1UV1fHvHnz4tFHHx3RYgEAImQRAKC0ZBEAKE9FFyatra2xdu3a2LhxY3R0dMSKFSti5cqV0dnZOez8o0ePxk033RQrVqyIjo6O+Pa3vx1r1qyJZ5999iMvHgBIjywCAJSSLAIA5asiy7KsmAuWLl0aixYtim3btg2MzZ8/P1atWhUtLS1D5n/rW9+KF198MQ4fPjww1tTUFL/85S9j3759F/WcfX19USgUore3N2pqaopZLgCUrVTPR1kEAMaHVM9HWQQAxoexOB8ri5l8+vTpOHDgQKxfv37QeENDQ+zdu3fYa/bt2xcNDQ2Dxm688cbYvn17vP/++zFlypQh1/T390d/f//Az729vRHxwQYAAB84fy4W+d6HCU0WAYDxQxb5P7IIAORvLLJIUYVJT09PnD17NmpraweN19bWRnd397DXdHd3Dzv/zJkz0dPTEzNmzBhyTUtLS2zevHnI+OzZs4tZLgAk4eTJk1EoFEq9jFzIIgAw/sgisggAlNJoZpGiCpPzKioqBv2cZdmQsT82f7jx8zZs2BDNzc0DP7/99tsxZ86c6OzsTCaElUpfX1/Mnj07jh075jbfMWav82Ov82W/89Pb2xtXX311XH755aVeSu5kkfLl35D82Ov82Ot82e/8yCL/RxYpH/4NyY+9zo+9zpf9zs9YZJGiCpPp06fH5MmTh7xr4sSJE0PeLXHelVdeOez8ysrKmDZt2rDXVFVVRVVV1ZDxQqHgjywnNTU19jon9jo/9jpf9js/kyZNKvUSciOLpMO/Ifmx1/mx1/my3/mRRWSRcuTfkPzY6/zY63zZ7/yMZhYp6jdNnTo16urqor29fdB4e3t71NfXD3vNsmXLhszftWtXLF68eNjP6QQAuBBZBAAoJVkEAMpb0dVLc3NzPPbYY7Fjx444fPhwrFu3Ljo7O6OpqSkiPrhtdPXq1QPzm5qa4o033ojm5uY4fPhw7NixI7Zv3x733Xff6L0KACAZsggAUEqyCACUr6K/w6SxsTFOnjwZW7Zsia6urliwYEG0tbXFnDlzIiKiq6srOjs7B+bPnTs32traYt26dfHII4/EzJkz4+GHH46vfOUrF/2cVVVVsWnTpmFvR2V02ev82Ov82Ot82e/8pLrXskh5s9f5sdf5sdf5st/5SXWvZZHyZq/zY6/zY6/zZb/zMxZ7XZGd/6YxAAAAAACARKXzzWwAAAAAAAAXoDABAAAAAACSpzABAAAAAACSpzABAAAAAACSN24Kk61bt8bcuXOjuro66urqYs+ePR86f/fu3VFXVxfV1dUxb968ePTRR3Na6cRXzF4/99xzccMNN8THP/7xqKmpiWXLlsUvfvGLHFc7sRX7d33eq6++GpWVlfH5z39+bBdYRord6/7+/ti4cWPMmTMnqqqq4pOf/GTs2LEjp9VObMXu9c6dO2PhwoVx6aWXxowZM+Kuu+6KkydP5rTaievll1+OW265JWbOnBkVFRXxwgsv/NFrnI0fjSySH1kkP7JIfmSR/Mgi+ZBF8ieL5EcWyY8skh9ZJD+ySD5KlkWyceDnP/95NmXKlOynP/1pdujQoezee+/NLrvssuyNN94Ydv6RI0eySy+9NLv33nuzQ4cOZT/96U+zKVOmZM8880zOK594it3re++9N/vud7+b/cd//Ef22muvZRs2bMimTJmS/dd//VfOK594it3r895+++1s3rx5WUNDQ7Zw4cJ8FjvBjWSvv/zlL2dLly7N2tvbs6NHj2b//u//nr366qs5rnpiKnav9+zZk02aNCn7wQ9+kB05ciTbs2dP9tnPfjZbtWpVziufeNra2rKNGzdmzz77bBYR2fPPP/+h852NH40skh9ZJD+ySH5kkfzIIvmRRfIli+RHFsmPLJIfWSQ/skh+SpVFxkVhsmTJkqypqWnQ2Kc//els/fr1w87/+7//++zTn/70oLGvfe1r2Re+8IUxW2O5KHavh/OZz3wm27x582gvreyMdK8bGxuzf/iHf8g2bdokGFykYvf6n//5n7NCoZCdPHkyj+WVlWL3+h//8R+zefPmDRp7+OGHs1mzZo3ZGsvRxQQDZ+NHI4vkRxbJjyySH1kkP7JIacgiY08WyY8skh9ZJD+ySH5kkdLIM4uU/CO5Tp8+HQcOHIiGhoZB4w0NDbF3795hr9m3b9+Q+TfeeGPs378/3n///TFb60Q3kr3+Q+fOnYtTp07F5ZdfPhZLLBsj3evHH388Xn/99di0adNYL7FsjGSvX3zxxVi8eHF873vfi6uuuiquvfbauO++++L3v/99HkuesEay1/X19XH8+PFoa2uLLMvizTffjGeeeSZuvvnmPJacFGfjyMki+ZFF8iOL5EcWyY8sMr45G0dOFsmPLJIfWSQ/skh+ZJHxbbTOxsrRXlixenp64uzZs1FbWztovLa2Nrq7u4e9pru7e9j5Z86ciZ6enpgxY8aYrXciG8le/6Hvf//78e6778att946FkssGyPZ69/85jexfv362LNnT1RWlvx/zQljJHt95MiReOWVV6K6ujqef/756Onpia9//evx1ltv+bzODzGSva6vr4+dO3dGY2Nj/M///E+cOXMmvvzlL8cPf/jDPJacFGfjyMki+ZFF8iOL5EcWyY8sMr45G0dOFsmPLJIfWSQ/skh+ZJHxbbTOxpLfYXJeRUXFoJ+zLBsy9sfmDzfOUMXu9XlPPfVUfOc734nW1ta44oorxmp5ZeVi9/rs2bNx2223xebNm+Paa6/Na3llpZi/63PnzkVFRUXs3LkzlixZEjfddFM89NBD8cQTT3g3xUUoZq8PHToUa9asiQceeCAOHDgQL730Uhw9ejSampryWGpynI0fjSySH1kkP7JIfmSR/Mgi45ez8aORRfIji+RHFsmPLJIfWWT8Go2zseR17fTp02Py5MlDWrgTJ04MaYTOu/LKK4edX1lZGdOmTRuztU50I9nr81pbW+Puu++Op59+Oq6//vqxXGZZKHavT506Ffv374+Ojo745je/GREfHF5ZlkVlZWXs2rUrrrvuulzWPtGM5O96xowZcdVVV0WhUBgYmz9/fmRZFsePH49rrrlmTNc8UY1kr1taWmL58uVx//33R0TE5z73ubjssstixYoV8eCDD3rn2yhyNo6cLJIfWSQ/skh+ZJH8yCLjm7Nx5GSR/Mgi+ZFF8iOL5EcWGd9G62ws+R0mU6dOjbq6umhvbx803t7eHvX19cNes2zZsiHzd+3aFYsXL44pU6aM2VonupHsdcQH76C4884748knn/T5ehep2L2uqamJX/3qV3Hw4MGBR1NTU3zqU5+KgwcPxtKlS/Na+oQzkr/r5cuXx+9+97t45513BsZee+21mDRpUsyaNWtM1zuRjWSv33vvvZg0afBRM3ny5Ij4v5af0eFsHDlZJD+ySH5kkfzIIvmRRcY3Z+PIySL5kUXyI4vkRxbJjywyvo3a2VjUV8SPkZ///OfZlClTsu3bt2eHDh3K1q5dm1122WXZf//3f2dZlmXr16/Pbr/99oH5R44cyS699NJs3bp12aFDh7Lt27dnU6ZMyZ555plSvYQJo9i9fvLJJ7PKysrskUceybq6ugYeb7/9dqlewoRR7F7/oU2bNmULFy7MabUTW7F7ferUqWzWrFnZX/3VX2W//vWvs927d2fXXHNNds8995TqJUwYxe71448/nlVWVmZbt27NXn/99eyVV17JFi9enC1ZsqRUL2HCOHXqVNbR0ZF1dHRkEZE99NBDWUdHR/bGG29kWeZsHG2ySH5kkfzIIvmRRfIji+RHFsmXLJIfWSQ/skh+ZJH8yCL5KVUWGReFSZZl2SOPPJLNmTMnmzp1arZo0aJs9+7dA//tjjvuyL74xS8Omv+v//qv2Z//+Z9nU6dOzT7xiU9k27Zty3nFE1cxe/3FL34xi4ghjzvuuCP/hU9Axf5d//8Eg+IUu9eHDx/Orr/++uySSy7JZs2alTU3N2fvvfdezquemIrd64cffjj7zGc+k11yySXZjBkzsr/+67/Ojh8/nvOqJ55/+Zd/+dB/f52No08WyY8skh9ZJD+ySH5kkXzIIvmTRfIji+RHFsmPLJIfWSQfpcoiFVnm3h8AAAAAACBtJf8OEwAAAAAAgFJTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMlTmAAAAAAAAMn7fyCO4gCxWlqFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "dataset = 'GunPoint'\n",
    "\n",
    "def visualize_experiment_1(dataset,model, ts, train):\n",
    "\n",
    "    for model in ['fcn_mt_ae','fcn_mt_conv']: #['fcn_mt_ae','fcn_mt_conv', 'fcn_mt_linear']: \n",
    "        model_type = model.split('_')[0] \n",
    "        ylen = 1 \n",
    "        idx = 0 if  train else 2\n",
    "        data = read_dataset(data_p, archive, dataset, 'original', ylen)[dataset]\n",
    "        #assertion,each ts has same length\n",
    "        ylen = len(data[0][0])\n",
    "        ig_data_stl  = read_dataset(data_p, archive, dataset, f'{model_type}_ig_norm', ylen)[dataset]\n",
    "\n",
    "        ig_link  = f'./results/ucr/{dataset}/experiment_1/{model_type}/{model}_{itr}/{model_type}_ig_norm/last_model.hdf5'\n",
    "        #cam_model =keras.models.load_model(cam_link ,compile=False)\n",
    "        ig_model = keras.models.load_model(ig_link ,compile=False)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "        fig = plt.gcf()\n",
    "        \n",
    "        #diff between train and test\n",
    "\n",
    "        #Get x values\n",
    "        x = ig_data_stl[idx]\n",
    "        #Get attribution froms singeltask values\n",
    "        stl_att = ig_data_stl[idx+1]\n",
    "        #Get predicted values\n",
    "        pred = ig_model.predict(x)[1]\n",
    "        #Get attribution values used for prediction\n",
    "        stl_pred_att = calculate_ig_attributions(data_p, archive, f\"{model}_0\", dataset, f\"{model_type}_ig_norm\", task=1)\n",
    "        #Get attributen used for specific time series\n",
    "        pred_att = stl_pred_att[0 if t == 1 else 1]\n",
    "\n",
    "        #First row raw attribution vector: \n",
    "        axes[0].plot(norm(stl_att[ts]), label=\"train\", linewidth=3)\n",
    "        axes[0].set_title('Train Attribution')\n",
    "        axes[1].plot(norm(pred[ts]), label=\"predicted\", color='orange')\n",
    "        axes[1].set_title('Prediction')\n",
    "        axes[2].plot(norm(stl_att[ts]), linewidth=3)\n",
    "        axes[2].plot(norm(pred[ts]), )\n",
    "        axes[2].set_title('Comparison of all Attributions')\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "        fig = plt.gcf()\n",
    "\n",
    "        #Second row visulaization\n",
    "        print(x[ts].shape,stl_att[ts].shape)\n",
    "        #transformed x-values,y-values,attributionvalues for visualization only!\n",
    "        xv,yv,av =prepare_visualize_attribution(x[ts],norm(stl_att[ts]))\n",
    "        axes[0].scatter(xv,yv,c=av, cmap='jet', vmin=0,vmax=100, s=1, label='train')\n",
    "        axes[0].set_title('Train Attribution')\n",
    "        xv,yv,av =prepare_visualize_attribution(x[ts],norm(pred[ts]))\n",
    "        axes[1].scatter(xv,yv,c=av, cmap='jet', vmin=0,vmax=100,s=1, label='attributed')\n",
    "        axes[1].set_title(\"Prediction\")\n",
    "        #axes[1][3].plot()\n",
    "\n",
    "        #plt.legend()\n",
    "        plt.show()\n",
    "        plt.draw()\n",
    "\n",
    "visualize_experiment_1('ECG200','resnet_mt_ae',10, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fidelity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/GunPoint//experiment_1/fcn/fcn_1/original/best_model.hdf5\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/GunPoint//experiment_1/resnet/resnet_1/original/best_model.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "5/5 [==============================] - 1s 20ms/step\n",
      "5/5 [==============================] - 0s 18ms/step\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/ECG200//experiment_1/fcn/fcn_1/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/ECG200//experiment_1/resnet/resnet_1/original/best_model.hdf5\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/Beef//experiment_1/fcn/fcn_1/original/best_model.hdf5\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "G:/Meine Ablage/master thesis/code/xai-tsc//results/ucr/Beef//experiment_1/resnet/resnet_1/original/best_model.hdf5\n",
      "1/1 [==============================] - 0s 461ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024F1C2F7370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 482ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import calculate_accuaracy_change\n",
    "from utils.explanations import calculate_ig_attributions\n",
    "from utils.utils import read_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "archive_name = 'ucr'\n",
    "\n",
    "\n",
    "#classifier = 'fcn_1'\n",
    "classifier = 'fcn_mt_nn_iter_0.5_0'\n",
    "cl_type = \"fcn\"\n",
    "root_dir = \"G:/Meine Ablage/master thesis/code/xai-tsc/\"\n",
    "itr = 1\n",
    "appendix = 'original'\n",
    "dataset_name = 'ECG200'\n",
    "\n",
    "results  = pd.DataFrame(columns=[\"dataset\",\"fcn_lerf\",\"fcn_morf\",\"resnet_lerf\", \"resnet_morf\"])\n",
    "\n",
    "results = []\n",
    "for dataset_name in [\"GunPoint\", \"ECG200\",\"Beef\"]:\n",
    "    lerf_morf = [dataset_name]\n",
    "    for classifier in [\"fcn_1\",\"resnet_1\"]: \n",
    "        cl_type = classifier.split(\"_\")[0]\n",
    "        att = calculate_ig_attributions(root_dir, archive_name, classifier, dataset_name, 'original', task=0, scale='norm', experiment=1)\n",
    "        x_train,y_train,x_test,y_test = read_dataset(root_dir, archive_name, dataset_name, 'original', 1)[dataset_name]\n",
    "        loaded_model = keras.models.load_model(f\"./results/ucr/{dataset_name}/experiment_1/{cl_type}/{classifier}/original/best_model.hdf5\", compile=False)\n",
    "        raw_att = [a[2] for a in att[1]]\n",
    "        #pred_raw_att = loaded_model.predict(x_test)[1]\n",
    "        # pred_raw_att = [a.flatten() for a in pred_raw_att]\n",
    "        #print(raw_att.shape)\n",
    "        lerf_change, morf_change = calculate_accuaracy_change(loaded_model,x_test,y_test,raw_att, mtl=False)\n",
    "        lerf_morf.append([lerf_change, morf_change])\n",
    "    results.append(lerf_morf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boent\\AppData\\Local\\Temp\\ipykernel_3056\\345039900.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  pd.DataFrame(new_results,columns=[\"dataset\",\"fcn_lerf\",\"fcn_morf\",\"resnet_lerf\", \"resnet_morf\"]).to_latex(\"./results_csv/Experiment1a/results_lerf_morf.tex\")\n"
     ]
    }
   ],
   "source": [
    "new_results = []\n",
    "for r in results: \n",
    "    new_results.append([r[0],*r[1],*r[2]])\n",
    "\n",
    "pd.DataFrame(new_results,columns=[\"dataset\",\"fcn_lerf\",\"fcn_morf\",\"resnet_lerf\", \"resnet_morf\"]).to_latex(\"./results_csv/Experiment1a/results_lerf_morf.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-tsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
