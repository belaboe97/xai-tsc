{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from utils.explanations import minmax_norm\n",
    "from utils.utils import read_dataset\n",
    "from utils.constants import CAM_LAYERS\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.explanations import calculate_cam_attributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "#from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.utils import CustomObjectScope\n",
    "def load_model(root_dir, archive_name, dataset_name, classifier, data_source): \n",
    "    with CustomObjectScope({'InstanceNormalization':tfa.layers.InstanceNormalization()}):\n",
    "        model_path = f'{root_dir}/results/{archive_name}/{dataset_name}/' \\\n",
    "                                                + f'{classifier.split(\"_\")[0]}/{classifier}/{data_source}/' \\\n",
    "                                                + f'best_model.hdf5'\n",
    "        model =keras.models.load_model(model_path ,compile=False)\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "root_dir ='G:/Meine Ablage/master thesis/code/xai-tsc'\n",
    "archive_name = 'ucr'\n",
    "classifier = 'fcn_1.0'\n",
    "dataset_name = 'Beef'\n",
    "data_source = 'original'\n",
    "\n",
    "data = read_dataset(root_dir, 'ucr', dataset_name,  data_source, 1)[dataset_name]\n",
    "\n",
    "base_model = load_model(root_dir, archive_name, dataset_name, classifier, data_source)\n",
    "\n",
    "#G:\\Meine Ablage\\master thesis\\code\\xai-tsc\\results\\ucr\\GunPoint\\fcn\\fcn_mt_dense_0.5d\n",
    "\n",
    "classifier = 'fcn_mt_dense_0.75'\n",
    "data_source = 'fcn_raw'\n",
    "dataset_name = 'GunPoint'\n",
    "data_source = 'fcn_raw_mse'\n",
    "\n",
    "sigmoid_model =  load_model(root_dir, archive_name, dataset_name, classifier, data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470,)\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Functional' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sigmoid_model[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Functional' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import CAM_LAYERS\n",
    "from utils.explanations import get_layer_index\n",
    "\n",
    "\n",
    "bact = CAM_LAYERS[classifier.split(\"_\")[0]][\"gap_layer\"]\n",
    "bact = get_layer_index(base_model, bact)\n",
    "\n",
    "sact = CAM_LAYERS[classifier.split(\"_\")[0]][\"gap_layer\"]\n",
    "sact = get_layer_index(sigmoid_model, sact)\n",
    "\n",
    "bnew_input_layer = base_model.inputs\n",
    "bnew_output_layer = [base_model.layers[bact].output]\n",
    "bew_feed_forward = keras.backend.function(bnew_input_layer, bnew_output_layer)\n",
    "\n",
    "\n",
    "sew_input_layer = sigmoid_model.inputs\n",
    "sew_output_layer = [sigmoid_model.layers[sact].output]\n",
    "sew_feed_forward = keras.backend.function(sew_input_layer, sew_output_layer)\n",
    "\n",
    "\n",
    "ts = data[0]\n",
    "\n",
    "[bconv_out] = bew_feed_forward([ts])\n",
    "[sconv_out] = sew_feed_forward([ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_corr = 0\n",
    "highest_filter_corr = 0\n",
    "for i in range(128):\n",
    "    #print(np.corrcoef(bconv_out[0][i],sconv_out[0][i]))\n",
    "    mean_corr += np.corrcoef(bconv_out[0][i],sconv_out[0][i])\n",
    "    for j in range(128):\n",
    "        #print(np.corrcoef(bconv_out[0][i],sconv_out[0][i]))\n",
    "        if np.corrcoef(bconv_out[0][i],sconv_out[0][i])[0,1] > highest_filter_corr:\n",
    "            highest_filter_corr = np.corrcoef(bconv_out[0][i],sconv_out[0][i])[0,1] \n",
    "\n",
    "\n",
    "print(mean_corr / 128, highest_filter_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filter(model):\n",
    "    import tensorflow.keras as keras\n",
    "    root_dir ='G:/Meine Ablage/master thesis/code/xai-tsc'\n",
    "    archive_name = 'ucr'\n",
    "    classifier = 'fcn_1.0'\n",
    "    dataset_name = 'GunPoint'\n",
    "    data_source = 'original'\n",
    "    datasets_dict = read_dataset(root_dir, 'ucr', dataset_name,  data_source, 1)\n",
    "    x_train = datasets_dict[dataset_name][0]\n",
    "    y_train = datasets_dict[dataset_name][1]\n",
    "\n",
    "    print(x_train.shape)\n",
    "\n",
    "    # filters\n",
    "    filters = model.layers[1].get_weights()[0]\n",
    "\n",
    "    new_input_layer = model.inputs\n",
    "    new_output_layer = [model.layers[1].output]\n",
    "\n",
    "    new_feed_forward = keras.backend.function(new_input_layer, new_output_layer)\n",
    "\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    colors = [(255 / 255, 160 / 255, 14 / 255), (181 / 255, 87 / 255, 181 / 255)]\n",
    "    colors_conv = [(210 / 255, 0 / 255, 0 / 255), (27 / 255, 32 / 255, 101 / 255)]\n",
    "\n",
    "    idx = 10\n",
    "    idx_filter = 10\n",
    "\n",
    "    filter = filters[:, 0, idx_filter]\n",
    "\n",
    "    print(\"Filter\",filter)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(filter + 0.5, color='gray', label='filter')\n",
    "    arr = []\n",
    "    for c in classes:\n",
    "        print(np.where(y_train == c))\n",
    "        c_x_train = x_train[np.where(y_train == c)[0]]\n",
    "        print(c_x_train.shape)\n",
    "        convolved_filter_1 = new_feed_forward([c_x_train])[0]\n",
    "        arr.append(convolved_filter_1)\n",
    "        idx_c = int(c) - 1\n",
    "        for f in range(128):\n",
    "        #plt.plot(c_x_train[idx], color=colors[idx_c], label='class' + str(idx_c) + '-raw')\n",
    "            plt.plot(convolved_filter_1[idx, :, f], color=colors_conv[idx_c], label='class' + str(idx_c) + '-conv')\n",
    "        #plt.legend()\n",
    "\n",
    "    root_dir = \"./\"\n",
    "    plt.savefig(root_dir + 'convolution-' + dataset_name + classifier + '.pdf')\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 150)\n",
      "Filter [ 0.04862259 -0.0022816   0.04238752  0.01836677 -0.01380017  0.0750989\n",
      " -0.08303187 -0.18231207]\n",
      "(array([ 2,  3,  9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 24, 26, 27, 29, 30,\n",
      "       33, 35, 41, 42, 43, 46, 48], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0], dtype=int64))\n",
      "(24, 150)\n",
      "(array([ 0,  1,  4,  5,  6,  7,  8, 14, 16, 17, 19, 23, 25, 28, 31, 32, 34,\n",
      "       36, 37, 38, 39, 40, 44, 45, 47, 49], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0], dtype=int64))\n",
      "(26, 150)\n"
     ]
    }
   ],
   "source": [
    "arr0 = visualize_filter(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filter(model, yval=data[1]):\n",
    "    import tensorflow.keras as keras\n",
    "    root_dir ='G:/Meine Ablage/master thesis/code/xai-tsc'\n",
    "    archive_name = 'ucr'\n",
    "    classifier = 'fcn_mt_dense_0.0'\n",
    "    data_source = 'fcn_minmax'\n",
    "    dataset_name = 'Beef'\n",
    "    datasets_dict = read_dataset(root_dir, 'ucr', dataset_name,  data_source, 470)\n",
    "    x_train = datasets_dict[dataset_name][0]\n",
    "    y_train = yval\n",
    "\n",
    "    print(x_train.shape)\n",
    "\n",
    "    # filters\n",
    "    filters = model.layers[1].get_weights()[0]\n",
    "\n",
    "    new_input_layer = model.inputs\n",
    "    new_output_layer = [model.layers[1].output]\n",
    "\n",
    "    new_feed_forward = keras.backend.function(new_input_layer, new_output_layer)\n",
    "    \n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    colors = [(255 / 255, 160 / 255, 14 / 255), (181 / 255, 87 / 255, 181 / 255)]\n",
    "    colors_conv = [(210 / 255, 0 / 255, 0 / 255), (27 / 255, 32 / 255, 101 / 255)]\n",
    "\n",
    "    idx = 4\n",
    "    idx_filter = 5\n",
    "\n",
    "    filter = filters[:, 0, idx_filter]\n",
    "    print(\"FILTER\", filter)\n",
    "    plt.figure()\n",
    "    plt.plot(filter + 0.5, color='gray', label='filter')\n",
    "\n",
    "    arr = []\n",
    "    for c in classes:\n",
    "        print(np.where(y_train == c))\n",
    "        c_x_train = x_train[np.where(y_train == c)[0]]\n",
    "        print(c_x_train.shape)\n",
    "        convolved_filter_1 = new_feed_forward([c_x_train])[0]\n",
    "\n",
    "        arr.append(convolved_filter_1)\n",
    "\n",
    "        idx_c = int(c) - 1\n",
    "        for f in range(10):\n",
    "        #plt.plot(c_x_train[idx], color=colors[idx_c], label='class' + str(idx_c) + '-raw')\n",
    "            plt.plot(convolved_filter_1[idx, :, f], color=colors_conv[idx_c], label='class' + str(idx_c) + '-conv')\n",
    "        #plt.plot(c_x_train[idx], color=colors[idx_c], label='class' + str(idx_c) + '-raw')\n",
    "        \n",
    "        #plt.plot(convolved_filter_1[idx, :, idx_filter], color=colors_conv[idx_c], label='class' + str(idx_c) + '-conv')\n",
    "        #plt.legend()\n",
    "\n",
    "    root_dir = \"./\"\n",
    "    plt.savefig(root_dir + 'convolution-' + dataset_name + classifier+ \"t\"+ '.pdf')\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 470)\n",
      "FILTER [-0.09121471 -0.05040509 -0.06130533 -0.01264581  0.10143563  0.06047529\n",
      "  0.0205708   0.12233275]\n",
      "(array([0, 1, 2, 3, 4, 5], dtype=int64), array([0, 0, 0, 0, 0, 0], dtype=int64))\n",
      "(6, 470)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"model_80\" is incompatible with the layer: expected shape=(None, 150, 1), found shape=(6, 470)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[246], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m arr1 \u001b[39m=\u001b[39m visualize_filter(sigmoid_model)\n",
      "Cell \u001b[1;32mIn[245], line 40\u001b[0m, in \u001b[0;36mvisualize_filter\u001b[1;34m(model, yval)\u001b[0m\n\u001b[0;32m     38\u001b[0m c_x_train \u001b[39m=\u001b[39m x_train[np\u001b[39m.\u001b[39mwhere(y_train \u001b[39m==\u001b[39m c)[\u001b[39m0\u001b[39m]]\n\u001b[0;32m     39\u001b[0m \u001b[39mprint\u001b[39m(c_x_train\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 40\u001b[0m convolved_filter_1 \u001b[39m=\u001b[39m new_feed_forward([c_x_train])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     42\u001b[0m arr\u001b[39m.\u001b[39mappend(convolved_filter_1)\n\u001b[0;32m     44\u001b[0m idx_c \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(c) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\keras\\backend.py:4630\u001b[0m, in \u001b[0;36mfunction.<locals>.func\u001b[1;34m(model_inputs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(model_inputs):\n\u001b[1;32m-> 4630\u001b[0m     outs \u001b[39m=\u001b[39m model(model_inputs)\n\u001b[0;32m   4631\u001b[0m     \u001b[39mif\u001b[39;00m wrap_outputs:\n\u001b[0;32m   4632\u001b[0m         outs \u001b[39m=\u001b[39m [outs]\n",
      "File \u001b[1;32mc:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\boent\\anaconda3\\envs\\xai-tsc\\lib\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"model_80\" is incompatible with the layer: expected shape=(None, 150, 1), found shape=(6, 470)"
     ]
    }
   ],
   "source": [
    "arr1 = visualize_filter(sigmoid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 150, 128)\n",
      "(26, 150, 128)\n",
      "0.4839307032093153\n"
     ]
    }
   ],
   "source": [
    "for i in arr1: \n",
    "    print(i.shape)\n",
    "\n",
    "highest_match = 0\n",
    "ix = None\n",
    "ij = None\n",
    "for i in range(128): \n",
    "    for j in range(128):\n",
    "        if highest_match < (np.corrcoef(arr0[0][0][i],arr1[0][0][j]))[0,1]: \n",
    "            highest_match = (np.corrcoef(arr0[0][0][i],arr1[0][0][j]))[0,1]\n",
    "            ix = i \n",
    "            ij = j \n",
    "print(highest_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 54)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix, ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'fcn_mt_dense_0.0'\n",
    "data_source = 'fcn_minmax_mse'\n",
    "dataset_name = 'Beef'\n",
    "\n",
    "\n",
    "\n",
    "dense_model_t =  load_model(root_dir, archive_name, dataset_name, classifier, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 470)\n",
      "FILTER [-0.13518423 -0.08784258 -0.09750187 -0.04375723  0.08166257  0.04844217\n",
      "  0.01836685  0.11919203]\n",
      "(array([0, 1, 2, 3, 4, 5], dtype=int64), array([0, 0, 0, 0, 0, 0], dtype=int64))\n",
      "(6, 470)\n",
      "(array([ 6,  7,  8,  9, 10, 11], dtype=int64), array([0, 0, 0, 0, 0, 0], dtype=int64))\n",
      "(6, 470)\n",
      "(array([12, 13, 14, 15, 16, 17], dtype=int64), array([0, 0, 0, 0, 0, 0], dtype=int64))\n",
      "(6, 470)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[251], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m arr2 \u001b[39m=\u001b[39m visualize_filter(dense_model_t)\n",
      "Cell \u001b[1;32mIn[250], line 47\u001b[0m, in \u001b[0;36mvisualize_filter\u001b[1;34m(model, yval)\u001b[0m\n\u001b[0;32m     44\u001b[0m     idx_c \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(c) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     45\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m     46\u001b[0m     \u001b[39m#plt.plot(c_x_train[idx], color=colors[idx_c], label='class' + str(idx_c) + '-raw')\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m         plt\u001b[39m.\u001b[39mplot(convolved_filter_1[idx, :, f], color\u001b[39m=\u001b[39mcolors_conv[idx_c], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(idx_c) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-conv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[39m#plt.plot(c_x_train[idx], color=colors[idx_c], label='class' + str(idx_c) + '-raw')\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \n\u001b[0;32m     50\u001b[0m     \u001b[39m#plt.plot(convolved_filter_1[idx, :, idx_filter], color=colors_conv[idx_c], label='class' + str(idx_c) + '-conv')\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39m#plt.legend()\u001b[39;00m\n\u001b[0;32m     53\u001b[0m root_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "arr2 = visualize_filter(dense_model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7286358455286505 52 52\n"
     ]
    }
   ],
   "source": [
    "highest_match = 0\n",
    "ix = None\n",
    "ij = None\n",
    "meanf = 0\n",
    "for i in range(128): \n",
    "    for j in range(128):\n",
    "        if highest_match < (np.corrcoef(arr0[0][0][i],arr2[0][0][j]))[0,1]: \n",
    "            highest_match = (np.corrcoef(arr0[0][0][i],arr2[0][0][j]))[0,1]\n",
    "            ix = i \n",
    "            ij = j \n",
    "print(highest_match,ix,ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0[0][0][52].mean(),arr2[0][0][52].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 790)\n",
      "FILTER [-0.13518423 -0.08784258 -0.09750187 -0.04375723  0.08166257  0.04844217\n",
      "  0.01836685  0.11919203]\n",
      "(array([ 2,  3,  9, 10, 11, 12, 13, 15, 18, 20, 21, 22, 24, 26, 27, 29, 30,\n",
      "       33, 35, 41, 42, 43, 46, 48], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0], dtype=int64))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 0 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m arr1 \u001b[39m=\u001b[39m visualize_filter(dense_model_t)\n",
      "Cell \u001b[1;32mIn[229], line 38\u001b[0m, in \u001b[0;36mvisualize_filter\u001b[1;34m(model, yval)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m classes:\n\u001b[0;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mwhere(y_train \u001b[39m==\u001b[39m c))\n\u001b[1;32m---> 38\u001b[0m     c_x_train \u001b[39m=\u001b[39m x_train[np\u001b[39m.\u001b[39;49mwhere(y_train \u001b[39m==\u001b[39;49m c)[\u001b[39m0\u001b[39;49m]]\n\u001b[0;32m     39\u001b[0m     \u001b[39mprint\u001b[39m(c_x_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     40\u001b[0m     convolved_filter_1 \u001b[39m=\u001b[39m new_feed_forward([c_x_train])[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 30 is out of bounds for axis 0 with size 30"
     ]
    }
   ],
   "source": [
    "arr1 = visualize_filter(dense_model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8971725667984465"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "def compare_filters_similarity(model1, model2, layer_index):\n",
    "    filters1 = model1.layers[layer_index].get_weights()[0]\n",
    "    filters2 = model2.layers[layer_index].get_weights()[0]\n",
    "    print(filters1.shape)\n",
    "    num_filters = filters1.shape[2]\n",
    "    total_similarity = 0.0\n",
    "\n",
    "    # Calculate similarity between filters\n",
    "    for i in range(num_filters):\n",
    "        max_similarity = 0.0\n",
    "        for j in range(num_filters):\n",
    "            filter1_i = filters1[:, :, i].flatten()\n",
    "            filter2_j = filters2[:, :, j].flatten()\n",
    "            #print(pearsonr(filter1_i, filter2_j)[0])\n",
    "            similarity =  pearsonr(filter1_i, filter2_j)[0] #1 -cosine(filter1_i, filter2_j)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "        total_similarity += max_similarity\n",
    "\n",
    "    average_similarity = total_similarity / num_filters\n",
    "\n",
    "    return average_similarity\n",
    "\n",
    "compare_filters_similarity(base_model, dense_model_t, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-tsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
